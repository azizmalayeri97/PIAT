{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PINN High Dim",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpbReTEo2eoj"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v3joQxTVolY"
      },
      "source": [
        "!pip install pyDOE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIRv0qITcsln"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUxrBgOUf2CA"
      },
      "source": [
        "import os\n",
        "os.chdir('./gdrive/MyDrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIzC5AFvZQXX"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "from pyDOE import lhs\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0Wi0AboZSE4"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "entbDSl7Mj4B"
      },
      "source": [
        "def equi_distant(dims, count):\n",
        "    if dims == 1:\n",
        "        return np.linspace(0, 1, count + 2)[1:-1].reshape(-1, 1)\n",
        "    if dims == 2:\n",
        "        count = int(np.ceil(np.sqrt(count)))\n",
        "        line = np.linspace(0, 1, count + 2)[1:-1]\n",
        "        x, y = np.meshgrid(line, line)\n",
        "        return np.stack([x.reshape(-1), y.reshape(-1)], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZemq2jOZaPT"
      },
      "source": [
        "# U(x, t) = sin(Ax)cos(Bt)\n",
        "DIM_A = 1\n",
        "B = 2\n",
        "SEED = 1\n",
        "torch.manual_seed(SEED)\n",
        "A = torch.randn((1, DIM_A)).to(device)\n",
        "BATCH_SIZE = 4096\n",
        "\n",
        "MODEL_NAME = 'AL.CA-2'\n",
        "N0 =100\n",
        "N1 = 10000\n",
        "N_TEST = 5000\n",
        "\n",
        "MIN_X = 0\n",
        "MAX_X = np.pi \n",
        "\n",
        "EPOCHS = 20000\n",
        "LOG_EVERY_EPOCH = int(EPOCHS/100)\n",
        "PLOT_EVERY_EPOCH = int(EPOCHS/5)\n",
        "\n",
        "LAYERS = 5\n",
        "NEURONS_PER_LAYER = 80\n",
        "\n",
        "GRAD_CLIP_VALUE = 5\n",
        "#ATTACK_TYPE = 'None'\n",
        "ATTACK_TYPE = 'Linf_change_label_high_dim'\n",
        "#ATTACK_TYPE = 'Gaussian'\n",
        "\n",
        "ATTACK_STEPS = 8\n",
        "ATTACK_EPS = 0.01\n",
        "ATTACK_DELTA = (ATTACK_EPS / 8) * 1.5\n",
        "\n",
        "EVAL_ATTACK_STEPS = 8\n",
        "EVAL_ATTACK_EPS = 0.05\n",
        "EVAL_ATTACK_DELTA = (ATTACK_EPS / 8) * 1.5\n",
        "\n",
        "sampling_func = lhs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8apgHNf4PII"
      },
      "source": [
        "writer = SummaryWriter(f'./PINN/HD/logs/{MODEL_NAME}/')\n",
        "hyper_writer = SummaryWriter('./PINN/HD/SUMMARY/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LcBmutqZgjo"
      },
      "source": [
        "D0 = []\n",
        "Y0 = []\n",
        "\n",
        "for i in range(DIM_A + 1):\n",
        "    x = torch.tensor(sampling_func(DIM_A + 1, N0) * (MAX_X - MIN_X) + MIN_X).to(device)\n",
        "    x[:, i] = 0\n",
        "    y = torch.cos(B * x[:, -1]) * torch.sin((A * x[:, :-1]).sum(dim=1))\n",
        "    D0.append(x)\n",
        "    Y0.append(y)\n",
        "\n",
        "for i in range(DIM_A):\n",
        "    x = torch.tensor(sampling_func(DIM_A + 1, N0) * (MAX_X - MIN_X) + MIN_X).to(device)\n",
        "    x[:, i] = MAX_X\n",
        "    y = torch.cos(B * x[:, -1]) * torch.sin((A * x[:, :-1]).sum(dim=1))\n",
        "    D0.append(x)  # list of 51 dim vectors [(X11, X12, ... X1M), .... (XN1, ...XNM)]\n",
        "    Y0.append(y)\n",
        "\n",
        "\n",
        "D0 = torch.cat(D0)  # matrix of shape (Num samples, 51)\n",
        "# [(X11, X12, ... X1M), \n",
        "#   .... \n",
        "#  (XN1, ..., XNM)]\n",
        "Y0 = torch.cat(Y0).reshape(-1, 1)\n",
        "boundary_dataset = TensorDataset(D0, Y0)\n",
        "boundary_loader = DataLoader(boundary_dataset, BATCH_SIZE, shuffle=True)\n",
        "\n",
        "D_tr = torch.tensor(sampling_func(DIM_A + 1, N1) * (MAX_X - MIN_X) + MIN_X).to(device)\n",
        "Y_tr = (torch.cos(B * D_tr[:, -1]) * torch.sin((A * D_tr[:, :-1]).sum(dim=1))).reshape(-1, 1)\n",
        "\n",
        "f = -B * torch.sin(B * D_tr[:, -1]) * torch.sin((A * D_tr[:, :-1]).sum(1)) + \\\n",
        "    (A ** 2).sum() * torch.cos(B * D_tr[:, -1]) * torch.sin((A * D_tr[:, :-1]).sum(1)) - \\\n",
        "    (torch.cos(B * D_tr[:, -1]) * torch.sin((A * D_tr[:, :-1]).sum(1))) + (torch.cos(B * D_tr[:, -1]) * torch.sin((A * D_tr[:, :-1]).sum(1)))**3\n",
        "f = f.reshape(-1)\n",
        "\n",
        "train_dataset = TensorDataset(D_tr, f)\n",
        "train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\n",
        "\n",
        "train_function_dataset = TensorDataset(D_tr, Y_tr)\n",
        "train_function_loader = DataLoader(train_function_dataset, BATCH_SIZE, shuffle=True)\n",
        "\n",
        "D_tst = torch.tensor(sampling_func(DIM_A + 1, N1) * (MAX_X - MIN_X) + MIN_X).to(device)\n",
        "Y_tst = (torch.cos(B * D_tst[:, -1]) * torch.sin((A * D_tst[:, :-1]).sum(dim=1))).reshape(-1, 1)\n",
        "test_dataset = TensorDataset(D_tst, Y_tst)\n",
        "test_loader = DataLoader(test_dataset, BATCH_SIZE, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpH-lx2jZYEO"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_shape, output_shape, layers, neurons_per_layer):\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.fc1 = nn.Linear(input_shape, neurons_per_layer)\n",
        "        for i in range(layers - 2):\n",
        "            layer = nn.Linear(neurons_per_layer, neurons_per_layer)\n",
        "            setattr(self, f'fc{i + 2}', layer)\n",
        "        layer = nn.Linear(neurons_per_layer, output_shape)\n",
        "        setattr(self, f'fc{layers}', layer)\n",
        "\n",
        "        self.activation =  nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(self.layers - 1):\n",
        "            layer = getattr(self, f'fc{i + 1}')\n",
        "            x = layer(x)\n",
        "            x = self.activation(x)\n",
        "        layer = getattr(self, f'fc{self.layers}')\n",
        "        x = layer(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLXDYyOUZdLd"
      },
      "source": [
        "def derivative(u_, x_, on_dim=1, order=1):\n",
        "    ones_ = torch.ones_like(u_)\n",
        "\n",
        "    drv = torch.autograd.grad(u_, x_, create_graph=True, grad_outputs=ones_)[0]\n",
        "    for i in range(1, order):\n",
        "        ones_ = torch.zeros_like(drv)\n",
        "        ones_[:, on_dim] = 1\n",
        "        drv = torch.autograd.grad(drv, x_, create_graph=True, grad_outputs=ones_)[0]\n",
        "    return drv\n",
        "\n",
        "\n",
        "def l2_pgd(x, target, loss_function, steps, eps, delta):\n",
        "    noise = torch.zeros_like(x).requires_grad_(True)\n",
        "    for i in range(steps):\n",
        "      loss = loss_function(x + noise, target)\n",
        "      loss.backward()\n",
        "      with torch.no_grad():\n",
        "        grad = noise.grad\n",
        "        grad /= torch.norm(grad, p=2, dim=1, keepdim=True)  # p=float('inf')\n",
        "        noise += grad * delta\n",
        "        norm2 = torch.norm(noise, p=2, dim=1, keepdim=True)   # p=float('inf')\n",
        "        norm2 = torch.maximum(norm2, torch.ones_like(norm2) * eps)\n",
        "        noise *= eps / norm2\n",
        "        noise.grad.zero_()\n",
        "    return noise\n",
        "  \n",
        "\n",
        "def gaussian_noise(x, target, loss_function, steps, eps, delta):\n",
        "    noise = torch.randn(x.size()).requires_grad_(True) * eps / np.sqrt(x.size(1))\n",
        "    return noise\n",
        "\n",
        "\n",
        "def zero_noise(x, *args, **kwargs):\n",
        "    return torch.zeros_like(x).requires_grad_(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNlMVbx4NcwC"
      },
      "source": [
        "eps_final= 0.2\n",
        "\n",
        "def Linf_change_label_high_dim(x, target, loss_function, steps, eps = (MAX_X-MIN_X)*eps_final, type_points='D0'):\n",
        "\n",
        "    if steps>0:\n",
        "      delta = (eps/steps)*1.5\n",
        "    noise = torch.zeros_like(x).requires_grad_(True)\n",
        "\n",
        "    for i in range(steps):\n",
        "      \n",
        "      #print(i, (x + noise).shape, target.shape)\n",
        "      loss = loss_function(x + noise, target)\n",
        "      loss.backward()\n",
        "      with torch.no_grad():\n",
        "        grad = noise.grad\n",
        "        grad = grad.sign()\n",
        "\n",
        "        noise += grad * delta\n",
        "\n",
        "        noise[noise>eps] = eps\n",
        "        noise[noise<-eps] = -eps\n",
        "        \n",
        "        noise.grad.zero_()\n",
        "\n",
        "      x_noise = x+noise\n",
        "      if type_points=='D0':\n",
        "          target = []\n",
        "          for i in range(1):\n",
        "              y = torch.cos(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(dim=1))\n",
        "              target.append(y)\n",
        "          #print(torch.tensor(target).shape)\n",
        "          target = torch.cat(target).reshape(-1, 1)\n",
        "          #print(target.shape)\n",
        "\n",
        "      elif type_points=='D_tr' or type_points=='D_tst':        \n",
        "        #target = (torch.cos(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(dim=1))).reshape(-1, 1)\n",
        "        target = -B * torch.sin(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(1)) + \\\n",
        "            (A ** 2).sum() * torch.cos(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(1)) - \\\n",
        "            (torch.cos(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(1))) + (torch.cos(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(1)))**3\n",
        "        target = target.reshape(-1)\n",
        "\n",
        "    return noise.detach(), target.detach()\n",
        "\n",
        "\n",
        "def Linf_change_label_gussaian_high_dim(x, target, loss_function, steps, eps = (MAX_X-MIN_X)*eps_final, type_points='D0'):\n",
        "\n",
        "    if steps>0:\n",
        "      noise = torch.randn(x.size(), device=device).requires_grad_(True)*eps\n",
        "\n",
        "      noise[noise>(MAX_X-x)] = MAX_X-x[noise>(MAX_X-x)]\n",
        "      noise[noise<(MIN_X-x)] = MIN_X-x[noise<(MIN_X-x)] \n",
        "\n",
        "      x_noise = x+noise\n",
        "      if type_points=='D0':\n",
        "          target = []\n",
        "          for i in range(1):\n",
        "              y = torch.cos(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(dim=1))\n",
        "              target.append(y)\n",
        "          #print(torch.tensor(target).shape)\n",
        "          target = torch.cat(target).reshape(-1, 1)\n",
        "          #print(target.shape)\n",
        "\n",
        "      elif type_points=='D_tr' or type_points=='D_tst':        \n",
        "        #target = (torch.cos(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(dim=1))).reshape(-1, 1)\n",
        "        target = -B * torch.sin(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(1)) + \\\n",
        "            (A ** 2).sum() * torch.cos(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(1)) - \\\n",
        "            (torch.cos(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(1))) + (torch.cos(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(1)))**3\n",
        "        target = target.reshape(-1)\n",
        "    \n",
        "    else:\n",
        "        noise = torch.zeros(x.size(), device=device).requires_grad_(True)\n",
        "      \n",
        "    return noise, target.detach()\n",
        "\n",
        "\n",
        "def Linf_without_change_label_gussaian_high_dim(x, target, loss_function, steps, eps = (MAX_X-MIN_X)*eps_final, type_points='D0'):\n",
        "\n",
        "    if steps>0:\n",
        "      noise = torch.randn(x.size(), device=device).requires_grad_(True)*eps\n",
        "\n",
        "      noise[noise>(MAX_X-x)] = MAX_X-x[noise>(MAX_X-x)]\n",
        "      noise[noise<(MIN_X-x)] = MIN_X-x[noise<(MIN_X-x)] \n",
        "\n",
        "      x_noise = x\n",
        "      if type_points=='D0':\n",
        "          target = []\n",
        "          for i in range(1):\n",
        "              y = torch.cos(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(dim=1))\n",
        "              target.append(y)\n",
        "          #print(torch.tensor(target).shape)\n",
        "          target = torch.cat(target).reshape(-1, 1)\n",
        "          #print(target.shape)\n",
        "\n",
        "      elif type_points=='D_tr' or type_points=='D_tst':        \n",
        "        #target = (torch.cos(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(dim=1))).reshape(-1, 1)\n",
        "        target = -B * torch.sin(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(1)) + \\\n",
        "            (A ** 2).sum() * torch.cos(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(1)) - \\\n",
        "            (torch.cos(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(1))) + (torch.cos(B * x_noise[:, -1]) * torch.sin((A * x_noise[:, :-1]).sum(1)))**3\n",
        "        target = target.reshape(-1)\n",
        "    \n",
        "    else:\n",
        "        noise = torch.zeros(x.size(), device=device).requires_grad_(True)\n",
        "      \n",
        "    return noise, target.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK6URYm_Nbg2"
      },
      "source": [
        "if ATTACK_TYPE == 'Gaussian':\n",
        "    attack_function = gaussian_noise\n",
        "elif ATTACK_TYPE == 'L2PGD':\n",
        "    attack_function = l2_pgd\n",
        "elif ATTACK_TYPE == 'Linf_change_label_high_dim':\n",
        "    attack_function = Linf_change_label_high_dim\n",
        "elif ATTACK_TYPE == 'Linf_change_label_gussaian_high_dim':\n",
        "    attack_function = Linf_change_label_gussaian_high_dim\n",
        "elif ATTACK_TYPE == 'Linf_without_change_label_gussaian_high_dim':\n",
        "    attack_function = Linf_without_change_label_gussaian_high_dim\n",
        "else:\n",
        "    attack_function = zero_noise\n",
        "print(attack_function)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s3yhFZD3DE8"
      },
      "source": [
        "# %matplotlib inline\n",
        "# import matplotlib.pyplot as plt\n",
        "# from mpl_toolkits import mplot3d\n",
        "\n",
        "# fig = plt.figure(figsize=plt.figaspect(0.5) * 1.5)\n",
        "# ax = fig.add_subplot(1, 2, 1, projection=\"3d\")\n",
        "# X = np.linspace(MIN_X, MAX_X, 100)\n",
        "# T = np.linspace(MIN_X, MAX_X, 100)\n",
        "# X, T = np.meshgrid(X, T)\n",
        "# a = A.cpu().numpy()[0]\n",
        "# u = torch.tensor(np.stack([X.reshape(-1), T.reshape(-1)], 1)).to(device)\n",
        "# Z = model(u).cpu().detach().numpy()\n",
        "# U = np.sin(a * X) * np.cos(B * T)\n",
        "# Z = Z.reshape(X.shape)\n",
        "# ax.plot_surface (X, T, Z\n",
        "#                 , rstride=1 # default value is one\n",
        "#                 , cstride=1 # default value is one\n",
        "#                 , cmap='winter'\n",
        "#                 , edgecolor='none'\n",
        "#                 )\n",
        "# ax.scatter3D(D_tr[:, 0].cpu().detach().numpy(),\n",
        "#               D_tr[:, 1].cpu().detach().numpy(),\n",
        "#               Y_tr[:, 0].cpu().detach().numpy(),\n",
        "#               marker='x')\n",
        "# ax.scatter3D(D0[:, 0].cpu().detach().numpy(),\n",
        "#               D0[:, 1].cpu().detach().numpy(),\n",
        "#               Y0[:, 0].cpu().detach().numpy(),\n",
        "#               marker='x')\n",
        "# ax.set_xlabel('X')\n",
        "# ax.set_ylabel('T')\n",
        "# ax.set_zlabel('Z')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZOZEDrOZiKs"
      },
      "source": [
        "model = Model(DIM_A + 1, 1, LAYERS, NEURONS_PER_LAYER).to(device).double()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),0.001)\n",
        "#optimizer = optim.SGD(model.parameters(), 0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, int(EPOCHS/10), 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9__fL8Z2csvO"
      },
      "source": [
        "def mse_output_target(x, y):\n",
        "    u = model(x)\n",
        "    return F.mse_loss(u, y)\n",
        "#u_t=u_xx+u-u^3+f\n",
        "#u(x,0)=f1(x)\n",
        "#u(0,t)=g(t)\n",
        "#u(1,t)=h(t)\n",
        "# let y=sin(x+t)\n",
        "#y=exact solution \n",
        "#f=(y)_t-(y_xx+y-(y)^3)\n",
        "def mse_derivatives(x, f):\n",
        "    u = model(x)\n",
        "\n",
        "    u_d = derivative(u, x)\n",
        "    u_t = u_d[:, -1]\n",
        "\n",
        "    #u_t - lap u\n",
        "    for i in range(DIM_A):\n",
        "        u_dd_i = derivative(u, x, i, 2)\n",
        "        u_xx_i = u_dd_i[:, i]\n",
        "        u_t -= u_xx_i \n",
        "  #   u_t - lap u - u + u3\n",
        "    u_t = u_t - u + u**3\n",
        "\n",
        "    #f=u_t-u_xx\n",
        "    '''\n",
        "    f = -B * torch.sin(B * x[:, -1]) * torch.sin((A * x[:, :-1]).sum(1)) + \\\n",
        "        (A ** 2).sum() * torch.cos(B * x[:, -1]) * torch.sin((A * x[:, :-1]).sum(1)) - \\\n",
        "        (torch.cos(B * x[:, -1]) * torch.sin((A * x[:, :-1]).sum(1))) + (torch.cos(B * x[:, -1]) * torch.sin((A * x[:, :-1]).sum(1)))**3\n",
        "    f = f.reshape(-1)\n",
        "    '''\n",
        "    return F.mse_loss(u_t, f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5rNnkBZ4a9l"
      },
      "source": [
        "%reload_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ikz5TrjWMrb"
      },
      "source": [
        "!ps | grep tensorbaord"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFe_FnJcndRn"
      },
      "source": [
        "%tensorboard --logdir ./PINN/HD/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj3vJ77sVY0g"
      },
      "source": [
        "epoch_start = time.time()\n",
        "previous_loss = None\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    train_boundary_loss = 0\n",
        "    train_collocation_loss = 0\n",
        "\n",
        "    #if epoch <= int(EPOCHS/2):\n",
        "    #    eps=(MAX_X-MIN_X)*eps_final*epoch/int(EPOCHS/2)\n",
        "    #else:\n",
        "    #    eps=(MAX_X-MIN_X)*eps_final\n",
        "    eps=(MAX_X-MIN_X)*eps_final\n",
        "\n",
        "    for i, (x, y) in enumerate(boundary_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #noise_u0t = attack_function(x, y, mse_output_target, ATTACK_STEPS, ATTACK_EPS, ATTACK_DELTA)\n",
        "        #noise_u0t, y = attack_function(x, y, mse_output_target, ATTACK_STEPS, ATTACK_EPS, 'D0')\n",
        "        noise_u0t, y = Linf_change_label_high_dim(x, y, mse_output_target, ATTACK_STEPS, eps, type_points='D0')\n",
        "        loss_0 = mse_output_target(x + noise_u0t, y)\n",
        "        train_boundary_loss += loss_0.item() * x.size(0)\n",
        "\n",
        "        loss_0.backward()\n",
        "        nn.utils.clip_grad_value_(model.parameters(), GRAD_CLIP_VALUE)\n",
        "        optimizer.step()\n",
        "\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #noise_u = attack_function(x, None, mse_derivatives, ATTACK_STEPS, ATTACK_EPS, ATTACK_DELTA)\n",
        "      #  noise_u, y = attack_function(x, y, mse_derivatives, ATTACK_STEPS, eps, 'D_tr')\n",
        "        noise_u, y = Linf_change_label_high_dim(x, y, mse_derivatives, ATTACK_STEPS, eps, type_points='D_tr')\n",
        "        adv_input = x + noise_u\n",
        "        adv_input.requires_grad = True\n",
        "\n",
        "        loss_1 = mse_derivatives(adv_input, y)\n",
        "        train_collocation_loss += loss_1 * x.size(0)\n",
        "\n",
        "        loss_1.backward()\n",
        "        nn.utils.clip_grad_value_(model.parameters(), GRAD_CLIP_VALUE)\n",
        "        optimizer.step()\n",
        "\n",
        "    train_boundary_loss /= len(boundary_loader.dataset)\n",
        "    train_collocation_loss /= len(train_loader.dataset)\n",
        "    total_train_loss = train_boundary_loss + train_collocation_loss\n",
        "\n",
        "    writer.add_scalars('loss', {\n",
        "        'Total': total_train_loss,\n",
        "        'Boundary': train_boundary_loss,\n",
        "        'Collocation': train_collocation_loss\n",
        "    }, epoch)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    if epoch % LOG_EVERY_EPOCH == 0:\n",
        "        print('Epoch', epoch)\n",
        "        model.eval()\n",
        "\n",
        "        function_loss = 0\n",
        "        for i, (x, y) in enumerate(train_function_loader):\n",
        "            u = model(x)\n",
        "            function_loss += F.mse_loss(u, y).item() * x.size(0)\n",
        "        function_loss /= len(train_loader.dataset)\n",
        "        print(f'Training loss {total_train_loss}, function loss {function_loss}')\n",
        "\n",
        "\n",
        "        clean_test_function_loss = 0\n",
        "        adv_test_function_loss = 0\n",
        "        for i, (x, y) in enumerate(test_loader):\n",
        "            #noise_test = attack_function(x, None, mse_derivatives, ATTACK_STEPS, ATTACK_EPS, ATTACK_DELTA)\n",
        "            #noise_test, y = attack_function(x, y, mse_derivatives, ATTACK_STEPS, ATTACK_EPS, 'D_tst')\n",
        "            u_test = model(x)\n",
        "            clean_test_function_loss += F.mse_loss(u_test, y).item() * x.size(0)\n",
        "            #u_test_adv = model(x + noise_test)\n",
        "            #adv_test_function_loss += F.mse_loss(u_test_adv, y).item() * x.size(0)\n",
        "        clean_test_function_loss /= len(test_loader.dataset)\n",
        "        #adv_test_function_loss /= len(test_loader.dataset)\n",
        "        print(f'Test function loss: Clean {clean_test_function_loss}, '\n",
        "              #f'Adv {adv_test_function_loss}'\n",
        "              )\n",
        "        print('time', time.time() - epoch_start)\n",
        "        epoch_start = time.time()\n",
        "        writer.add_scalars('Function Loss', {\n",
        "            'Train': function_loss,\n",
        "            'Test': clean_test_function_loss,\n",
        "            #'Test Adv': adv_test_function_loss,\n",
        "        }, epoch)\n",
        "        writer.flush()\n",
        "    # if previous_loss is None or loss.item() < LAMBDA_PLOT * previous_loss or \\\n",
        "    #             epoch % PLOT_EVERY_EPOCH == 0:\n",
        "    #     plot_model(f'Epoch {epoch}', epoch)\n",
        "    #     previous_loss = loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDYBwDyKUT7V"
      },
      "source": [
        "def evaluate(loader):\n",
        "    function_loss = 0\n",
        "    for x, y in loader:\n",
        "       u = model(x)\n",
        "       function_loss += F.mse_loss(u, y).item()\n",
        "    function_loss /= len(loader.dataset)\n",
        "    return function_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHIquTU6or2V"
      },
      "source": [
        "'''\n",
        "model.eval()\n",
        "train_function_loss = evaluate(train_loader)\n",
        "print(f'Training loss {total_train_loss.item()}, function loss {train_function_loss}')\n",
        "\n",
        "\n",
        "clean_test_function_loss = 0\n",
        "adv_test_function_loss = 0\n",
        "for i, (x, y) in enumerate(test_loader):\n",
        "    noise_test = l2_pgd(x, None, mse_derivatives, EVAL_ATTACK_STEPS, EVAL_ATTACK_EPS, \n",
        "                    EVAL_ATTACK_DELTA)\n",
        "    u_test = model(x)\n",
        "    clean_test_function_loss += F.mse_loss(u_test, y).item() * x.size(0)\n",
        "    u_test_adv = model(x + noise_test)\n",
        "    adv_test_function_loss += F.mse_loss(u_test_adv, y).item() * x.size(0)\n",
        "clean_test_function_loss /= len(test_loader.dataset)\n",
        "adv_test_function_loss /= len(test_loader.dataset)\n",
        "\n",
        "print(f'Test function loss: Clean {clean_test_function_loss}, '\n",
        "      f'Adv {adv_test_function_loss}')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT1jY3ktelo5"
      },
      "source": [
        "hyper_writer.add_hparams(\n",
        "    {\n",
        "        'N0': N0,\n",
        "        'N1': N1,\n",
        "        'N_TEST': N_TEST,\n",
        "        'DIM_A': DIM_A,\n",
        "        'B': B,\n",
        "        'SEED': SEED,\n",
        "        'EPOCHS': EPOCHS,\n",
        "        'BATCH_SIZE': BATCH_SIZE,\n",
        "        'LAYERS': LAYERS,\n",
        "        'NEURONS_PER_LAYER': NEURONS_PER_LAYER,\n",
        "        'ATTACK_TYPE': ATTACK_TYPE,\n",
        "        'ATTACK_STEPS': ATTACK_STEPS,\n",
        "        'ATTACK_DELTA': ATTACK_DELTA,\n",
        "        'ATTACK_EPS': ATTACK_EPS,\n",
        "        'EVAL_ATTACK_STEPS': EVAL_ATTACK_STEPS, \n",
        "        'EVAL_ATTACK_EPS': EVAL_ATTACK_EPS,\n",
        "        'EVAL_ATTACK_DELTA': EVAL_ATTACK_DELTA,\n",
        "        'MIN_X': MIN_X,\n",
        "        'MAX_X': MAX_X,\n",
        "        'SAMPLING_FUNCTION': sampling_func.__name__,\n",
        "    },\n",
        "    {\n",
        "        'training_function_loss': train_function_loss,\n",
        "        'test_clean_function_loss': clean_test_function_loss,\n",
        "        'test_adv_function_loss': adv_test_function_loss,\n",
        "    },\n",
        "    run_name=MODEL_NAME,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c-Yt39EjyZW"
      },
      "source": [
        "writer.close()\n",
        "hyper_writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWKAQBgEmaxC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}