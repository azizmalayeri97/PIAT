{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PINN_KS_change_label.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWDm037wCcLx"
      },
      "source": [
        "!nvidia-smi -L\n",
        "!pip install pyDOE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaBN3PZ1pm6z"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "os.chdir('./gdrive/MyDrive/')\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESPfP-aFpsnR"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from pyDOE import lhs\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "import time\n",
        "from torch.utils.tensorboard import SummaryWriter \n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAXGO9vNHKL_"
      },
      "source": [
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)  # for multiGPUs.\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS859o1jpvbA"
      },
      "source": [
        "MODEL_NAME = 'test1lr0.1decay0'\n",
        "N0 = 20\n",
        "N1 = 2000\n",
        "N_TEST = 1000\n",
        "N_val = 500\n",
        "\n",
        "V = 0.5\n",
        "EPOCHS = 20000\n",
        "LOG_EVERY_EPOCH = 1000\n",
        "PLOT_EVERY_EPOCH = 2000\n",
        "\n",
        "LAYERS =5\n",
        "NEURONS_PER_LAYER = 100\n",
        "\n",
        "GRAD_CLIP_VALUE = 5\n",
        "\n",
        "ATTACK_STEPS = 8\n",
        "eps_final = 0.05\n",
        "attack_type = 'adv' # 'guassian' #or 'adv'\n",
        "\n",
        "sampling_func = lhs\n",
        "#sampling_func = equi_distant"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9oaabUmp3M5"
      },
      "source": [
        "def equi_distant(dims, count):\n",
        "    if dims == 1:\n",
        "        return np.linspace(0, 1, count + 2)[1:-1].reshape(-1, 1)\n",
        "    if dims == 2:\n",
        "        count = int(np.ceil(np.sqrt(count)))\n",
        "        line = np.linspace(0, 1, count + 2)[1:-1]\n",
        "        x, y = np.meshgrid(line, line)\n",
        "        return np.stack([x.reshape(-1), y.reshape(-1)], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK-XWlU2pwvv"
      },
      "source": [
        "writer = SummaryWriter(f'./PINN/KS_change_label/logs/{MODEL_NAME}/')\n",
        "hyper_writer = SummaryWriter('./PINN/KS_change_label/SUMMARY/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8hHgVQ-p0vl"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_shape, output_shape, layers, neurons_per_layer):\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.fc1 = nn.Linear(input_shape, neurons_per_layer)\n",
        "        for i in range(layers - 2):\n",
        "            layer = nn.Linear(neurons_per_layer, neurons_per_layer)\n",
        "            setattr(self, f'fc{i + 2}', layer)\n",
        "        layer = nn.Linear(neurons_per_layer, output_shape)\n",
        "        setattr(self, f'fc{layers}', layer)\n",
        "\n",
        "        # Activaiton Function\n",
        "        # self.activation = nn.LeakyReLU(0.1)\n",
        "        self.activation = nn.Tanh()\n",
        "        # self.activation = nn.ReLU()\n",
        "        # self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(self.layers - 1):\n",
        "            layer = getattr(self, f'fc{i + 1}')\n",
        "            x = layer(x)\n",
        "            x = self.activation(x)\n",
        "        layer = getattr(self, f'fc{self.layers}')\n",
        "        x = layer(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4mXseOYeJ2I"
      },
      "source": [
        "def derivative(u_, x_, order=1, ignore_dim=1):\n",
        "    ones_ = torch.ones_like(u_)\n",
        "    drv = torch.autograd.grad(u_, x_, create_graph=True, grad_outputs=ones_)[0]\n",
        "    for i in range(1, order):\n",
        "        ones_ = torch.ones_like(drv)\n",
        "        ones_[:, ignore_dim] = 0\n",
        "        drv = torch.autograd.grad(drv, x_, create_graph=True, grad_outputs=ones_)[0]\n",
        "    return drv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bdoJJ4dp4In"
      },
      "source": [
        "# (0, 20) x (0, 10)\n",
        "MIN_X = 0\n",
        "MAX_X = 20\n",
        "MIN_T = 0\n",
        "MAX_T = 1\n",
        "\n",
        "x = torch.tensor(sampling_func(1, N0) * (MAX_X - MIN_X) + MIN_X).to(device)\n",
        "zeros = torch.zeros_like(x)\n",
        "ones = torch.ones_like(x)\n",
        "\n",
        "D0 = torch.cat([x, zeros], 1)\n",
        "Y0 = torch.sin(x)\n",
        "\n",
        "D1 = torch.tensor(sampling_func(2, N1)).to(device)\n",
        "D1[:, 0] = D1[:, 0] * (MAX_X - MIN_X) + MIN_X\n",
        "D1[:, 1] = D1[:, 1] * (MAX_T - MIN_T) + MIN_T\n",
        "P1 = torch.tensor([2 * np.pi, 0]).to(device)\n",
        "\n",
        "D_tr = torch.tensor(sampling_func(2, N1)).to(device)\n",
        "D_tr[:, 0] = D_tr[:, 0] * (MAX_X - MIN_X) + MIN_X\n",
        "D_tr[:, 1] = D_tr[:, 1] * (MAX_T - MIN_T) + MIN_T\n",
        "Y_tr = torch.sin(D_tr[:, 0:1] + D_tr[:, 1:2])\n",
        "res_tr = torch.cos(D_tr[:, 0:1] + D_tr[:, 1:2]) * (1 + torch.sin(D_tr[:, 0:1] + D_tr[:, 1:2])) + (V - 1) * torch.sin(D_tr[:, 0:1] + D_tr[:, 1:2])\n",
        "\n",
        "D_val= torch.tensor(lhs(2, N_val)).to(device)\n",
        "D_val[:, 0] = D_val[:, 0] * (MAX_X - MIN_X) + MIN_X\n",
        "D_val[:, 1] = D_val[:, 1] * (MAX_T - MIN_T) + MIN_T\n",
        "Y_val = torch.sin(D_val[:, 0:1] + D_val[:, 1:2])\n",
        "res_val = torch.cos(D_val[:, 0:1] + D_val[:, 1:2]) * (\n",
        "    1 + torch.sin(D_val[:, 0:1] + D_val[:, 1:2])\n",
        ") + (V - 1) * torch.sin(D_val[:, 0:1] + D_val[:, 1:2])\n",
        "\n",
        "D_tst = torch.tensor(lhs(2, N_TEST)).to(device)\n",
        "D_tst[:, 0] = D_tst[:, 0] * (MAX_X - MIN_X) + MIN_X\n",
        "D_tst[:, 1] = D_tst[:, 1] * (MAX_T - MIN_T) + MIN_T\n",
        "Y_tst = torch.sin(D_tst[:, 0:1] + D_tst[:, 1:2])\n",
        "res_tst = torch.cos(D_tst[:, 0:1] + D_tst[:, 1:2]) * (\n",
        "    1 + torch.sin(D_tst[:, 0:1] + D_tst[:, 1:2])\n",
        ") + (V - 1) * torch.sin(D_tst[:, 0:1] + D_tst[:, 1:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyWlLI4yp6lB"
      },
      "source": [
        "model = Model(2, 1, LAYERS, NEURONS_PER_LAYER).to(device).double()\n",
        "#optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
        "optimizer = optim.Adamax(model.parameters(), lr=0.01, weight_decay=0)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.1,momentum=0.9)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, 1000, 0.5)\n",
        "#scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 50000, eta_min=0, last_epoch=-1, verbose=False)\n",
        "#scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc_s64DAp7lV"
      },
      "source": [
        "def mse_output_target(x, y):\n",
        "    u = model(x)\n",
        "    return F.mse_loss(u, y)\n",
        "\n",
        "\n",
        "def mse_periodic(x, y):\n",
        "    u = model(x)\n",
        "    x2 = x + y\n",
        "    u2 = model(x2)\n",
        "    return F.mse_loss(u, u2)\n",
        "\n",
        "\n",
        "def mse_residual(x, y):\n",
        "\n",
        "    x = x.requires_grad_(True)\n",
        "    u = model(x)\n",
        "    u_d = derivative(u, x)\n",
        "    u_dd = derivative(u, x, 2)\n",
        "    u_dddd = derivative(u, x, 4)\n",
        "\n",
        "    u_t = u_d[:, 1:2]\n",
        "    u_x = u_d[:, 0:1]\n",
        "    \n",
        "    u_xx = u_dd[:, 0:1]\n",
        "    u_xxxx = u_dddd[:, 0:1]\n",
        "\n",
        "    return F.mse_loss(u_t + u * u_x + u_xx + V * u_xxxx, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdROHfoo_XVe"
      },
      "source": [
        "#@title Plot\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "def plot_model(title=None, epoch=None):\n",
        "    fig = plt.figure(figsize=plt.figaspect(0.5) * 1.5)\n",
        "    ax = fig.add_subplot(1, 2, 1, projection=\"3d\")\n",
        "\n",
        "    X = np.linspace(MIN_X, MAX_X, 300)\n",
        "    T = np.linspace(MIN_T, MAX_T, 300)\n",
        "    X, T = np.meshgrid(X, T)\n",
        "    u = torch.tensor(np.stack([X.reshape(-1), T.reshape(-1)], 1)).to(device)\n",
        "    Z = model(u).cpu().detach().numpy()\n",
        "    U = np.sin(X + T)\n",
        "    Z = Z.reshape(X.shape)\n",
        "    ax.plot_surface (X, T, Z\n",
        "                    , rstride=1 # default value is one\n",
        "                    , cstride=1 # default value is one\n",
        "                    , cmap='winter'\n",
        "                    , edgecolor='none'\n",
        "                    )\n",
        "    ax.scatter3D(D_tr[:, 0].cpu().detach().numpy(),\n",
        "                 D_tr[:, 1].cpu().detach().numpy(),\n",
        "                 Y_tr[:, 0].cpu().detach().numpy(),\n",
        "                 marker='x')\n",
        "    ax.scatter3D(D0[:, 0].cpu().detach().numpy(),\n",
        "                 D0[:, 1].cpu().detach().numpy(),\n",
        "                 Y0[:, 0].cpu().detach().numpy(),\n",
        "                 marker='x')\n",
        "    \n",
        "    ax.set_xlabel('X')\n",
        "    ax.set_ylabel('T')\n",
        "    ax.set_zlabel('Z')\n",
        "    ax.set_title('Prediction');\n",
        "    ###############################\n",
        "    ax = fig.add_subplot(1, 2, 2, projection=\"3d\")\n",
        "    ax.plot_surface (X, T, U\n",
        "                    , rstride=1 # default value is one\n",
        "                    , cstride=1 # default value is one\n",
        "                    , cmap='winter'\n",
        "                    , edgecolor='none'\n",
        "                    )\n",
        "    ax.set_xlabel('X')\n",
        "    ax.set_ylabel('T')\n",
        "    ax.set_zlabel('Z')\n",
        "    ax.set_title('Actual');\n",
        "    if title is not None:\n",
        "        fig.suptitle(f'{title}')\n",
        "    if epoch is not None:\n",
        "        writer.add_figure(\n",
        "            'Function',\n",
        "            fig,\n",
        "            epoch,\n",
        "            close=False\n",
        "        )\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    fig = plt.figure(figsize=plt.figaspect(0.5) * 1.5)\n",
        "    ax = fig.add_subplot(1, 2, 1)\n",
        "\n",
        "    ax.contour  (X, T, Z\n",
        "                , cmap = plt.cm.autumn\n",
        "                )\n",
        "    ax.scatter(D_tr[:, 0].cpu().detach().numpy(),\n",
        "               D_tr[:, 1].cpu().detach().numpy(),\n",
        "               marker='x')\n",
        "    \n",
        "    ax.set_xlabel('X')\n",
        "    ax.set_ylabel('T')\n",
        "    ax.set_title('Prediction')\n",
        "\n",
        "    ##################################\n",
        "\n",
        "    ax = fig.add_subplot(1, 2, 2)\n",
        "    ax.contour  (X, T, U\n",
        "                , cmap = plt.cm.autumn\n",
        "                )\n",
        "    ax.set_xlabel('X')\n",
        "    ax.set_ylabel('T')\n",
        "    ax.set_title('Actual')\n",
        "    if epoch is not None:\n",
        "        writer.add_figure(\n",
        "            'Contour',\n",
        "            fig,\n",
        "            epoch,\n",
        "            close=False\n",
        "        )\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0ptUKwwbE5B"
      },
      "source": [
        "plot_model('init')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df6grDDFaq_R"
      },
      "source": [
        "#%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXl6FGQHtMTp"
      },
      "source": [
        "%reload_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUdkZ2KWymVh"
      },
      "source": [
        "!ps aux | grep tensorboard "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM_zv_xpri8_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2-3irw7rh7x"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOurpYw1auoi"
      },
      "source": [
        "%tensorboard --logdir ./PINN/KS_change_label/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V95BRUtnAysT"
      },
      "source": [
        "%cd '/content/'\n",
        "KSchangelabel_path = '/content/gdrive/MyDrive/KSchangelabel.pth' \n",
        "best_path_adv = '/content/gdrive/MyDrive/best_adv.pth' \n",
        "resume = 0\n",
        "\n",
        "start_epoch = 0\n",
        "min_error_adv = 999999\n",
        "if resume:\n",
        "    checkpoint = torch.load(KSchangelabel_path, map_location=torch.device('cpu')) #torch.load(KSchangelabel_path)\n",
        "    model.load_state_dict(checkpoint['net'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "    start_epoch = checkpoint['epoch']+1\n",
        "    min_error_adv = checkpoint['best_error']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC13crivaf_w"
      },
      "source": [
        "#ATTACK_STEPS = 8\n",
        "\n",
        "def attack(x, target, loss_function, steps, eps_1 = 20*eps_final, eps_2 = 1*eps_final):\n",
        "\n",
        "    eps = torch.ones_like(x)\n",
        "    eps[:, 0] = eps[:, 0] * eps_1\n",
        "    eps[:, 1] = eps[:, 1] * eps_2\n",
        "    delta = (eps/steps)*1.5\n",
        "\n",
        "    noise = torch.zeros_like(x).requires_grad_(True)\n",
        "    for i in range(steps):\n",
        "      loss = loss_function(x + noise, target)\n",
        "      loss.backward()\n",
        "      with torch.no_grad():\n",
        "        grad = noise.grad\n",
        "        #grad /= torch.norm(grad, p=2, dim=1, keepdim=True)  # p=float('inf')\n",
        "        grad = grad.sign()\n",
        "\n",
        "\n",
        "        noise += grad * delta\n",
        "        #norm2 = torch.norm(noise, p=2, dim=1, keepdim=True)   # p=float('inf')\n",
        "        #norm2 = torch.maximum(norm2, torch.ones_like(norm2) * eps)\n",
        "        #noise *= eps / norm2\n",
        "\n",
        "        noise[:, 0][noise[:, 0]>eps_1] = eps_1\n",
        "        noise[:, 0][noise[:, 0]<-eps_1] = -eps_1\n",
        "\n",
        "        noise[:, 1][noise[:, 1]>eps_2] = eps_2\n",
        "        noise[:, 1][noise[:, 1]<-eps_2] = -eps_2\n",
        "        #noise = torch.clamp(noise, min=-eps, max=eps)\n",
        "        \n",
        "        noise.grad.zero_()\n",
        "\n",
        "    return noise.detach()\n",
        "\n",
        "\n",
        "def attack_change_label(x, loss_function, steps, eps_1 = 20*eps_final, eps_2 = 1*eps_final, type_points='D0'):\n",
        "\n",
        "    eps = torch.ones_like(x)\n",
        "    eps[:, 0] = eps[:, 0] * eps_1\n",
        "    eps[:, 1] = eps[:, 1] * eps_2\n",
        "    delta = (eps/steps)*1.5\n",
        "\n",
        "    noise = torch.zeros_like(x).requires_grad_(True)\n",
        "    for i in range(steps):\n",
        "\n",
        "      if type_points=='D0':\n",
        "        target = torch.sin((x + noise)[:, 0].unsqueeze(1))\n",
        "      elif type_points=='D1':\n",
        "        target = torch.tensor([2 * np.pi, 0]).to(device)\n",
        "      elif type_points=='D_tr':\n",
        "        target = torch.cos((x + noise)[:, 0:1] + (x + noise)[:, 1:2]) * (1 + torch.sin((x + noise)[:, 0:1] + (x + noise)[:, 1:2])) + (V - 1) * torch.sin((x + noise)[:, 0:1] + (x + noise)[:, 1:2])\n",
        "\n",
        "      loss = loss_function(x + noise, target)\n",
        "      loss.backward()\n",
        "      with torch.no_grad():\n",
        "        grad = noise.grad\n",
        "        grad = grad.sign()\n",
        "\n",
        "\n",
        "        noise += grad * delta\n",
        "\n",
        "        noise[:, 0][noise[:, 0]>eps_1] = eps_1\n",
        "        noise[:, 0][noise[:, 0]<-eps_1] = -eps_1\n",
        "\n",
        "        noise[:, 0][noise[:, 0]>(MAX_X-x[:, 0])] = MAX_X-x[:, 0][noise[:, 0]>(MAX_X-x[:, 0])]\n",
        "        noise[:, 0][noise[:, 0]<(MIN_X-x[:, 0])] = MIN_X-x[:, 0][noise[:, 0]<(MIN_X-x[:, 0])] \n",
        "\n",
        "        noise[:, 1][noise[:, 1]>eps_2] = eps_2\n",
        "        noise[:, 1][noise[:, 1]<-eps_2] = -eps_2\n",
        "\n",
        "        noise[:, 1][noise[:, 1]>(MAX_T-x[:, 1])] = MAX_T-x[:, 1][noise[:, 1]>(MAX_T-x[:, 1])]\n",
        "        noise[:, 1][noise[:, 1]<(MIN_T-x[:, 1])] = MIN_T-x[:, 1][noise[:, 1]<(MIN_T-x[:, 1])] \n",
        "        \n",
        "        noise.grad.zero_()\n",
        "    \n",
        "    if type_points=='D0':\n",
        "      target = torch.sin((x + noise)[:, 0].unsqueeze(1))\n",
        "    elif type_points=='D1':\n",
        "      target = torch.tensor([2 * np.pi, 0]).to(device)\n",
        "    elif type_points=='D_tr':\n",
        "      target = torch.cos((x + noise)[:, 0:1] + (x + noise)[:, 1:2]) * (1 + torch.sin((x + noise)[:, 0:1] + (x + noise)[:, 1:2])) + (V - 1) * torch.sin((x + noise)[:, 0:1] + (x + noise)[:, 1:2])\n",
        "\n",
        "\n",
        "    return noise.detach(), target.detach()\n",
        "\n",
        "\n",
        "def attack_change_label_gussaian(x, loss_function, steps, eps_1 = 20*eps_final, eps_2 = 1*eps_final, type_points='D0'):\n",
        "\n",
        "    eps = torch.zeros_like(x)\n",
        "    eps[:, 0] = eps_1\n",
        "    eps[:, 1] = eps_2\n",
        "\n",
        "    noise = torch.randn(x.size(), device=device).requires_grad_(True) * eps\n",
        "\n",
        "    noise[:, 0][noise[:, 0]>(MAX_X-x[:, 0])] = MAX_X-x[:, 0][noise[:, 0]>(MAX_X-x[:, 0])]\n",
        "    noise[:, 0][noise[:, 0]<(MIN_X-x[:, 0])] = MIN_X-x[:, 0][noise[:, 0]<(MIN_X-x[:, 0])] \n",
        "\n",
        "    noise[:, 1][noise[:, 1]>(MAX_T-x[:, 1])] = MAX_T-x[:, 1][noise[:, 1]>(MAX_T-x[:, 1])]\n",
        "    noise[:, 1][noise[:, 1]<(MIN_T-x[:, 1])] = MIN_T-x[:, 1][noise[:, 1]<(MIN_T-x[:, 1])] \n",
        "\n",
        "    if type_points=='D0':\n",
        "      target = torch.sin((x + noise)[:, 0].unsqueeze(1))\n",
        "    elif type_points=='D1':\n",
        "      target = torch.tensor([2 * np.pi, 0]).to(device)\n",
        "    elif type_points=='D_tr':\n",
        "      target = torch.cos((x + noise)[:, 0:1] + (x + noise)[:, 1:2]) * (1 + torch.sin((x + noise)[:, 0:1] + (x + noise)[:, 1:2])) + (V - 1) * torch.sin((x + noise)[:, 0:1] + (x + noise)[:, 1:2])\n",
        "\n",
        "    return noise, target.detach()\n",
        "\n",
        "def attack_without_change_label_gussaian(x, loss_function, steps, eps_1 = 20*eps_final, eps_2 = 1*eps_final, type_points='D0'):\n",
        "\n",
        "    eps = torch.zeros_like(x)\n",
        "    eps[:, 0] = eps_1\n",
        "    eps[:, 1] = eps_2\n",
        "\n",
        "    noise = torch.randn(x.size(), device=device).requires_grad_(True) * eps\n",
        "\n",
        "    noise[:, 0][noise[:, 0]>(MAX_X-x[:, 0])] = MAX_X-x[:, 0][noise[:, 0]>(MAX_X-x[:, 0])]\n",
        "    noise[:, 0][noise[:, 0]<(MIN_X-x[:, 0])] = MIN_X-x[:, 0][noise[:, 0]<(MIN_X-x[:, 0])] \n",
        "\n",
        "    noise[:, 1][noise[:, 1]>(MAX_T-x[:, 1])] = MAX_T-x[:, 1][noise[:, 1]>(MAX_T-x[:, 1])]\n",
        "    noise[:, 1][noise[:, 1]<(MIN_T-x[:, 1])] = MIN_T-x[:, 1][noise[:, 1]<(MIN_T-x[:, 1])] \n",
        "\n",
        "    if type_points=='D0':\n",
        "      target = torch.sin((x)[:, 0].unsqueeze(1))\n",
        "    elif type_points=='D1':\n",
        "      target = torch.tensor([2 * np.pi, 0]).to(device)\n",
        "    elif type_points=='D_tr':\n",
        "      target = torch.cos((x)[:, 0:1] + (x)[:, 1:2]) * (1 + torch.sin((x)[:, 0:1] + (x)[:, 1:2])) + (V - 1) * torch.sin((x)[:, 0:1] + (x)[:, 1:2])\n",
        "\n",
        "    return noise, target.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTCYqEOb5mhS"
      },
      "source": [
        "if attack_type == 'attack_change_label_gussaian':\n",
        "  attack_type = attack_change_label_gussaian\n",
        "\n",
        "if attack_type == 'attack_without_change_label_gussaian':\n",
        "  attack_type = attack_without_change_label_gussaian\n",
        "\n",
        "elif attack_type == 'adv':\n",
        "  attack_type = attack_change_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj1Yhb_Nau5_"
      },
      "source": [
        "all_train_loss = []\n",
        "all_val_loss = []\n",
        "all_epochs = []\n",
        "\n",
        "print('Start epoch: ', start_epoch)\n",
        "epoch_start = time.time()\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch <= int(EPOCHS/2):\n",
        "        eps_1=eps_final*epoch/int(EPOCHS/2)\n",
        "        eps_2=eps_final*epoch/int(EPOCHS/2)\n",
        "    else:\n",
        "        eps_1=eps_final\n",
        "        eps_2=eps_final\n",
        "\n",
        "    #noise_ud0 = attack(D0, Y0, mse_output_target, ATTACK_STEPS, 20*eps_1, eps_2 = 0)\n",
        "    noise_ud0, noise_Y0 = attack_type(D0, mse_output_target, ATTACK_STEPS, 20*eps_1, eps_2 = 0, type_points='D0')\n",
        "    #noise_ud1 = attack(D1, P1, mse_periodic, ATTACK_STEPS, 20*eps_1, eps_2)\n",
        "    noise_ud1, noise_Y1 = attack_type(D1, mse_periodic, ATTACK_STEPS, 20*eps_1, eps_2, type_points='D1')\n",
        "    ud0 = model(D0 + noise_ud0)  # or u0t = model(torch.clamp(D0 + noise_u0t))\n",
        "    # ud1 = model(D1 + noise_ud1)\n",
        "    #loss_0 = F.mse_loss(ud0, Y0)\n",
        "    loss_0 = F.mse_loss(ud0, noise_Y0)\n",
        "    #loss_1 =  mse_periodic(D1 + noise_ud1, P1) ##check\n",
        "    loss_1 =  mse_periodic(D1 + noise_ud1, noise_Y1)\n",
        "\n",
        "\n",
        "    #noise_u = attack(D_tr, res_tr, mse_residual, ATTACK_STEPS, 20*eps_1, eps_2)\n",
        "    noise_u, noise_res_tr = attack_type(D_tr, mse_residual, ATTACK_STEPS, 20*eps_1, eps_2, type_points='D_tr')\n",
        "    adv_input = D_tr + noise_u ##check (add model)\n",
        "    #loss_2 = mse_residual(adv_input, res_tr)\n",
        "    loss_2 = mse_residual(adv_input, noise_res_tr)\n",
        "\n",
        "\n",
        "    #loss_check = [F.mse_loss(model(D0), Y0).mean().item(), mse_periodic(D1, P1).mean().item(), mse_residual(D_tr, res_tr).mean().item()]\n",
        "    #loss_check2 = [loss_0.mean().item(), loss_1.mean().item(), loss_2.mean().item()]\n",
        "    #print(loss_check, loss_check2)\n",
        "\n",
        "    loss = loss_0 + loss_1 + loss_2\n",
        "    writer.add_scalars('loss', {\n",
        "        'Total': loss.item(),\n",
        "        'Boundary': loss_0.item(),\n",
        "        'Periodic': loss_1.item(),\n",
        "        'Collocation': loss_2.item()\n",
        "    }, epoch)\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_value_(model.parameters(), GRAD_CLIP_VALUE)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    if epoch % LOG_EVERY_EPOCH == 0:\n",
        "        print('Epoch', epoch)\n",
        "        model.eval()\n",
        "        u = model(D_tr)\n",
        "        function_loss = F.mse_loss(u, Y_tr).item()\n",
        "        print(f'Training loss {loss.item()}, function loss {function_loss}')\n",
        "\n",
        "        noise_val, Y_new = attack_type(D_val, mse_residual, ATTACK_STEPS, 20*eps_1, eps_2, type_points='D_tr')\n",
        "        u_val = model(D_val)\n",
        "        val_function_loss = F.mse_loss(u_val, Y_val).item()\n",
        "        u_val_adv = model(D_val + noise_val)\n",
        "        adv_val_function_loss = F.mse_loss(u_val_adv, Y_new).item()\n",
        "        print(f'val function loss: Clean {val_function_loss}, '\n",
        "              f'Adv {adv_val_function_loss}')\n",
        "        print('time', time.time() - epoch_start)\n",
        "        epoch_start = time.time()\n",
        "        writer.add_scalars('Function Loss', {\n",
        "            'Train': function_loss,\n",
        "            'val': val_function_loss,\n",
        "            'val Adv': adv_val_function_loss,\n",
        "        }, epoch)\n",
        "        writer.flush()\n",
        "\n",
        "        all_train_loss.append(function_loss)\n",
        "        all_val_loss.append(val_function_loss)\n",
        "        all_epochs.append(epoch)\n",
        "        \n",
        "        if val_function_loss<min_error_adv:\n",
        "            min_error_adv = val_function_loss\n",
        "\n",
        "            state = {'net': model.state_dict(),\n",
        "              'epoch': epoch,\n",
        "              'optimizer': optimizer.state_dict(),\n",
        "              'scheduler': scheduler.state_dict(),\n",
        "              'best_error' : min_error_adv\n",
        "              }\n",
        "\n",
        "          \n",
        "            torch.save(state, best_path_adv)\n",
        "            print('checkpoint epoch: ', epoch)\n",
        "        \n",
        "        \n",
        "        \n",
        "    if epoch % PLOT_EVERY_EPOCH == 0:\n",
        "        plot_model(f'Epoch {epoch}', epoch)\n",
        "    \n",
        "    if epoch % 50 == 0:\n",
        "        state = {'net': model.state_dict(),\n",
        "              'epoch': epoch,\n",
        "              'optimizer': optimizer.state_dict(),\n",
        "              'scheduler': scheduler.state_dict(),\n",
        "              'best_error' : min_error_adv\n",
        "              }\n",
        "\n",
        "          \n",
        "        torch.save(state, KSchangelabel_path)\n",
        "        print('checkpoint epoch: ', epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "torch.save([all_train_loss,\n",
        "all_val_loss,\n",
        "all_epochs], 'KS_PIAT.pth')"
      ],
      "metadata": {
        "id": "Hkb-F_KOt1h6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dQbyk2oNapd"
      },
      "source": [
        "#Test\n",
        "\n",
        "checkpoint = torch.load(best_path_adv)\n",
        "model.load_state_dict(checkpoint['net'])\n",
        "\n",
        "model.eval()\n",
        "u = model(D_tr)\n",
        "function_loss = F.mse_loss(u, Y_tr).item()\n",
        "print(f'Training loss {loss.item()}, function loss {function_loss}')\n",
        "\n",
        "noise_test = attack(D_tst, res_tst, mse_residual, ATTACK_STEPS, 20*eps_1, eps_2)\n",
        "u_test = model(D_tst)\n",
        "test_function_loss = F.mse_loss(u_test, Y_tst).item()\n",
        "u_test_adv = model(D_tst + noise_test)\n",
        "adv_test_function_loss = F.mse_loss(u_test_adv, Y_tst).item()\n",
        "print(f'Test function loss: Clean {test_function_loss}, '\n",
        "      f'Adv {adv_test_function_loss}')\n",
        "print('time', time.time() - epoch_start)\n",
        "epoch_start = time.time()\n",
        "writer.add_scalars('Function Loss', {\n",
        "    'Train': function_loss,\n",
        "    'Test': test_function_loss,\n",
        "    'Test Adv': adv_test_function_loss,\n",
        "}, epoch)\n",
        "writer.flush()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrvX_f-BavKT"
      },
      "source": [
        "def evaluate(D, Y):\n",
        "    u = model(D)\n",
        "    function_loss = F.mse_loss(u, Y).item()\n",
        "    return function_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz1NbStzavQk"
      },
      "source": [
        "'''\n",
        "model.eval()\n",
        "train_function_loss = evaluate(D_tr, Y_tr)\n",
        "print(f'Training loss {loss.item()}, function loss {train_function_loss}')\n",
        "\n",
        "noise_test = attack(D_tst, res_tst, mse_residual, 8, 0.05, 0.01, 20*eps_1, eps_2)\n",
        "\n",
        "test_function_loss = evaluate(D_tst, Y_tst)\n",
        "\n",
        "adv_test_function_loss = evaluate(D_tst + noise_test, Y_tst)\n",
        "print(f'Test function loss: Clean {test_function_loss}, '\n",
        "      f'Adv {adv_test_function_loss}')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aITT4UWUavWR"
      },
      "source": [
        "'''\n",
        "hyper_writer.add_hparams(\n",
        "    {\n",
        "        'N0': N0,\n",
        "        'N1': N1,\n",
        "        'N_TEST': N_TEST,\n",
        "        'EPOCHS': EPOCHS,\n",
        "        'LAYERS': LAYERS,\n",
        "        'NEURONS_PER_LAYER': NEURONS_PER_LAYER,\n",
        "        'ATTACK_STEPS': ATTACK_STEPS,\n",
        "        'ATTACK_DELTA': ATTACK_DELTA,\n",
        "        'ATTACK_EPS': ATTACK_EPS,\n",
        "        'SAMPLING_FUNCTION': sampling_func.__name__,\n",
        "        'ACTIVATION_FUNCTION': str(model.activation),\n",
        "    #    'ATTACK_TYPE': str(ATTACK_TYPE),\n",
        "     \n",
        "    },\n",
        "    {\n",
        "        'training_function_loss': train_function_loss,\n",
        "        'test_clean_function_loss': test_function_loss,\n",
        "        'test_adv_function_loss': adv_test_function_loss,\n",
        "    }\n",
        ")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3o7EqYLbAPV"
      },
      "source": [
        "writer.close()\n",
        "hyper_writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}